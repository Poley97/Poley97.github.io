I"<blockquote>
  <p>论文链接 ： https://openaccess.thecvf.com/content_CVPRW_2019/papers/WAD/Paigwar_Attentional_PointNet_for_3D-Object_Detection_in_Point_Clouds_CVPRW_2019_paper.pdf</p>
</blockquote>

<blockquote>
  <p>参考博客 :</p>
</blockquote>

<p>所提出的网络主要包含以下部分：<strong>Context Network, Recurrent Localization Network, 3D Transformer, and Resampler, Classifier, 3D Box Estimation.</strong> 并且设计了一个独特的loss。</p>

<h2 id="context-network">Context Network</h2>
<p>输入一个cropped region（$12m\times 12m$）的3D点。和一个点云的2D垂直投影，在$120\times 120$的cell里。使用简化版的PointNet，也就是没有T-Net的来提取特征。</p>

<p><img src="/assets/img/20210529/APF3.png" alt="" /></p>

<p>Height map就是一个2D数据，直接用标准卷积即可。</p>

<p>这两种信息是互补的，3D可以帮助区别2D中容易混淆的物体。2D可以更直观的分辨3D中不好辨识的物体。</p>

<h2 id="recurrent-localization-network">Recurrent Localization Network</h2>

<p>使用一个<strong>GRU</strong>层来对特征进行处理，使用前面给出的特征以及上一次迭代的状态来产生此时刻的状态。然后估计一个刚性变换的5个参数。$\left(\cos \theta_{i}, \sin \theta_{i}, T x_{i}, T y_{i}, T z_{i}\right) \in \Theta_{i}$。得到一个刚性变换矩阵</p>

\[\begin{equation}
T\left(\Theta_{i}\right)=\left[\begin{array}{cccc}
\cos \theta_{i} &amp; -\sin \theta_{i} &amp; 0 &amp; T x_{i} \\
\sin \theta_{i} &amp; \cos \theta_{i} &amp; 0 &amp; T y_{i} \\
0 &amp; 0 &amp; 1 &amp; T z_{i} \\
0 &amp; 0 &amp; 0 &amp; 1
\end{array}\right]
\end{equation}\]

<p>这里只考虑刚性变换是因为和图像不同，3D目标的大小不会因为距离的变化而改变。</p>
:ET
I"<blockquote>
  <p>论文地址
参考地址</p>
</blockquote>

<h1 id="introduction">Introduction</h1>

<p>目前随着3D传感器技术的快速发展，激光雷达LiDAR已经呗广泛使用，每个LiDAR都可以产生一副点云，包含了周围环境的几何信息。但是激光雷达的limitations和复杂性：</p>

<ol>
  <li>环境的多样性</li>
  <li>物体遮挡和阶段</li>
  <li>不同类别间和size区别得到的不相似表示，以及同一种类别物体，距离不同得到的不同结果</li>
  <li>表现可靠性</li>
</ol>

<p>其余自动驾驶中常用的传感器也有各自的优势和劣势</p>
<ol>
  <li>Camera-based：可以提供高密度的像素信息，可以捕捉到形状和纹理信息。但是单目相机缺少深度信息，TOF和stereo cameras可以提供深度信息，但是要付出昂贵的计算成本。stereo cameras的深度信息的误差随着距离的上升指数上升，TOF的容易受到光照的影响。</li>
  <li>RADAR，相比LiDAR具有更低的分辨率和更小的视野。它的特殊性使得它更适合其他任务，比如速度判定，短距离目标检测或者自动停车。</li>
</ol>

<p><img src="/assets/img/20210526/PCReviewT1.png" alt="" /></p>

<p>点云处理的难点：</p>

<ol>
  <li>点云数据的特性，高维、系数、非结构化的数据；</li>
  <li>高性能要求，自动驾驶需要从点云中提取特征并进行检测和分类，在实时的条件下。典型的场景是10Hz；</li>
  <li>安装的限制，安装在车上的处理模块是资源有限的。</li>
</ol>

<h2 id="点云处理的pipeline-和分类">点云处理的Pipeline 和分类</h2>

<p>主要的流程分为三个模块：</p>
<ol>
  <li><strong>Data Representation</strong>：Voxels,Frustums，Pillars，2Dprojection or raw point cloud</li>
  <li><strong>Feature Extraction</strong>: 见图</li>
  <li><strong>Detection Network modules</strong>：见图</li>
  <li><strong>Predictions Refinement Network</strong>:见图</li>
</ol>

<p><img src="/assets/img/20210526/PCReviewF1.png" alt="" /></p>

<p><img src="/assets/img/20210526/PCReviewF2.png" alt="" /></p>

<p>本文的目录结构也按上述的分类展开。</p>

<h1 id="data-representation-approaches">Data representation approaches</h1>

<p>点云是非结构化的数据，为了应用基于CNN的目标检测方法，点云自然需要一个结构化的表示来应用卷积操作。</p>

<h2 id="point-based">Point-based</h2>

<p>直接对点云处理来得到稀疏的表示。典型就是<strong>PointNet</strong>，后续被拓展到提取局部和全局特征，并启发了其他的工作，比如<strong>Voxel Feature Extractor</strong>(VoxelNet提出)，并被用于一系列文献，such as IPO, STD, PointRCNN, PointRGCN, LaserNe, PointFusion, RoarNe and PointPaiting, resort to this scheme of point cloud representation。</p>

<h2 id="voxel-based">Voxel-based</h2>

<p>通过体素化减小点云的维度，节省内存，帮助特征提取网络更高效的利用一组点提取计算局部和全局（底层和高层）特征，而不是逐点计算。</p>

<h2 id="frustum-based">Frustum-based</h2>

<p>将点云切割到一个Frustum里，比如Frustum PointNet,Frustum ConvNet and SIFRNet。</p>

<h2 id="pillar-based">Pillar-based</h2>

<p>相当于简化的体素化，忽略了z轴，比如PointPillars。</p>

<h2 id="projection-based">Projection-based</h2>

<p>将3D投影到2D，来减小高维的计算量。有多种投影方式，比如<strong>front biew(FV), range view(RV), bird’s eye vies(BEV)</strong>。他们分别相当于沿着z轴（前），x轴（右）和y轴（上）进行压缩。</p>

<p>其中<strong>BEV应该是最适合自动驾驶的</strong>，因为感兴趣目标都在同一个地面上，具有比较小的方差，所以这也是使用的最广泛的方法。相比FV具有一些优点，比如解决了遮挡问题，并且可以保持物体本身的物理尺寸，具有较小的方差，这都是FV所不具备的能力。</p>
:ET
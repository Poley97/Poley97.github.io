I"<blockquote>
  <p>论文链接： https://openaccess.thecvf.com/content_cvpr_2018/papers/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.pdf
参考博客 ：</p>
</blockquote>

<h1 id="introduction">Introduction</h1>

<p>本文提出的无监督学习的新方法来自于物体识别领域的几个发现。在ImageNet上，top-5错误率远低于top-1错误率，并且置信度第二高的类别往往和图像本身具有较高的视觉关联。如下图所示</p>

<p><img src="/assets/img/20210601/UFLNPIDF1.png" alt="aaa" /></p>

<p>这样的发现说明discriminative learning method可以自动的发现语义类别中显著的相似性，而不需要特别的指引。<strong>也就是说，这种显著的相似性不是从语义标注中学到的，而是来自于视觉数据本身</strong>。</p>

<p>因此作者把class-wise的监督用到instance-wise的监督上，是否可以通过discriminative learning学习到一种Metric，来反应instance之间显著的相似性？每个image都以他们自己的形式被distinct，每个都显著的和同语义类别的其他images不一样。如果我们学会如何区分两个独立的instance，而不用任何语义类别，<strong>可能就可以得到一种捕捉instance间显著相似性的表达，就像class-wise捕捉类间相似性一样。</strong>。由于这个本身也是一个instance-level discrimination 的任务，所以也可以从最新的discriminative supervised learning中获得好处，比如新的网络结构。</p>

<p>但是，我们也遇到了一些问题，比如<strong>classes数量</strong>数量的激增。如果一个实例是一个类别，那么ImageNet可能有1.2M个类别而不是100类，因此softmax显得不再可行。因此使用一种方法来模拟softmax的分布，通过<strong>noise-contrastive estimation(NCE)</strong>,并利用一个<strong>proximal regularization</strong>来稳定学习过程。</p>
:ET